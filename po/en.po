msgid ""
msgstr ""
"Project-Id-Version: SNUCSE GPU Service Manual\n"
"POT-Creation-Date: \n"
"PO-Revision-Date: 2023-08-03 12:15+0900\n"
"Last-Translator:  <contact@bacchus.snucse.org>\n"
"Language-Team: English\n"
"Language: en\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"

#: src/SUMMARY.md:3 src/introduction.md:1
msgid "SNUCSE GPU 서비스"
msgstr ""

#: src/SUMMARY.md:7
msgid "운영 안내"
msgstr ""

#: src/SUMMARY.md:9 src/servers.md:1
msgid "서버 목록"
msgstr ""

#: src/SUMMARY.md:10 src/users.md:1
msgid "사용자 안내"
msgstr ""

#: src/SUMMARY.md:12
msgid "서버 접근 방법"
msgstr ""

#: src/SUMMARY.md:14 src/kubectl.md:1
msgid "kubectl 설치 및 설정"
msgstr ""

#: src/SUMMARY.md:15 src/kubelogin.md:1
msgid "kubelogin 설치 및 설정"
msgstr ""

#: src/SUMMARY.md:16 src/context.md:1
msgid "컨텍스트 설정 및 테스트"
msgstr ""

#: src/SUMMARY.md:18
msgid "서버 이용 방법"
msgstr ""

#: src/SUMMARY.md:20 src/quota.md:1
msgid "리소스 쿼터 설정"
msgstr ""

#: src/SUMMARY.md:21 src/container.md:1
msgid "컨테이너 실행"
msgstr ""

#: src/SUMMARY.md:22 src/volume.md:1
msgid "퍼시스턴트 볼륨 설정"
msgstr ""

#: src/SUMMARY.md:23 src/registry.md:1
msgid "이미지 레지스트리 이용"
msgstr ""

#: src/SUMMARY.md:24 src/example.md:1
msgid "워크플로우 예시"
msgstr ""

#: src/SUMMARY.md:28 src/developers.md:1
msgid "개발팀"
msgstr ""

#: src/introduction.md:5
msgid ""
"안녕하세요, 여러분과 함께하는 서울대학교 컴퓨터공학부 서버 관리자 모임 바쿠스"
"입니다."
msgstr ""

#: src/introduction.md:7
msgid ""
"바쿠스에서는 컴퓨터공학부 구성원들에게 GPU 서버를 무료로 제공하고 있습니다. "
"**A100 GPU** 서버를 이용하실 분들은 이 매뉴얼을 읽어주시기 바랍니다."
msgstr ""

#: src/introduction.md:9
msgid ""
"기타 문의사항은 <contact@bacchus.snucse.org>로 보내주시기 바랍니다. 감사합니"
"다."
msgstr ""

#: src/servers.md:3
msgid "이용 가능 서버"
msgstr ""

#: src/servers.md:5 src/servers.md:12 src/kubectl.md:13
msgid "서버명"
msgstr ""

#: src/servers.md:5 src/servers.md:12
msgid "GPU"
msgstr ""

#: src/servers.md:5 src/servers.md:12
msgid "vCPU"
msgstr ""

#: src/servers.md:5 src/servers.md:12
msgid "메모리"
msgstr ""

#: src/servers.md:5 src/servers.md:12
msgid "GPU P2P"
msgstr ""

#: src/servers.md:5 src/servers.md:12
msgid "스토리지"
msgstr ""

#: src/servers.md:7 src/kubectl.md:15
msgid "ferrari"
msgstr ""

#: src/servers.md:7 src/servers.md:14
msgid "(HGX A100)"
msgstr ""

#: src/servers.md:7 src/servers.md:8
msgid "8 x A100"
msgstr ""

#: src/servers.md:7 src/servers.md:14
msgid "(80GB HBM2E)"
msgstr ""

#: src/servers.md:7 src/servers.md:8
msgid "256"
msgstr ""

#: src/servers.md:7 src/servers.md:8
msgid "1024GB"
msgstr ""

#: src/servers.md:7 src/servers.md:8
msgid "NVSwitch"
msgstr ""

#: src/servers.md:7 src/servers.md:14
msgid "7.68TB"
msgstr ""

#: src/servers.md:8 src/kubectl.md:16
msgid "bentley"
msgstr ""

#: src/servers.md:8
msgid "(DGX A100)"
msgstr ""

#: src/servers.md:8
msgid "(40GB HBM2)"
msgstr ""

#: src/servers.md:8
msgid "15.36TB"
msgstr ""

#: src/servers.md:10
msgid "도입 예정 서버"
msgstr ""

#: src/servers.md:14
msgid "ford"
msgstr ""

#: src/servers.md:14
msgid "4 x A100"
msgstr ""

#: src/servers.md:14
msgid "64"
msgstr ""

#: src/servers.md:14
msgid "768GB"
msgstr ""

#: src/servers.md:14
msgid "NVLink"
msgstr ""

#: src/servers.md:16
msgid "주의"
msgstr ""

#: src/servers.md:18
msgid ""
"현재 기술적인 문제로 GPUDirect RDMA 및 GPUDirect Storage가 지원되지 않습니"
"다. 추후 지원될 예정입니다."
msgstr ""

#: src/users.md:3
msgid "대상"
msgstr ""

#: src/users.md:5
msgid "학부생"
msgstr ""

#: src/users.md:6
msgid "컴퓨터공학부 주전공생"
msgstr ""

#: src/users.md:7
msgid "자유전공학부 (컴퓨터공학 주전공) 학생"
msgstr ""

#: src/users.md:8
msgid "컴퓨터공학부 복수/부전공생"
msgstr ""

#: src/users.md:9
msgid "대학원생"
msgstr ""

#: src/users.md:10
msgid "컴퓨터공학부 대학원생"
msgstr ""

#: src/users.md:11
msgid "협동과정 인공지능 소속 중 지도교수가 컴퓨터공학부 소속인 대학원생"
msgstr ""

#: src/users.md:13
msgid ""
"ferrari 서버는 학부생, 대학원생 모두 이용할 수 있습니다. bentley 서버는 대학"
"원생만 이용할 수 있습니다."
msgstr ""

#: src/users.md:16 src/container.md:45 src/registry.md:5
msgid "주의사항"
msgstr ""

#: src/users.md:18
msgid ""
"모든 서버는 **연구 목적**으로만 사용 가능합니다. 바쿠스는 서버를 항시 모니터"
"링하고 있으며, 연구 목적 이외의 사용이 적발될 경우 서비스 이용에 불이익이 있"
"을 수 있습니다."
msgstr ""

#: src/users.md:20
msgid ""
"A100 GPU의 리소스가 많지 않으니 딥러닝 모델 사이즈가 크거나 학습이 시급한 경"
"우 등, A100이 필요한 경우에만 사용을 해주시기 바랍니다. 외부 클라우드나 서울"
"대학교 공과대학 GPU First 등과는 달리 모든 서비스가 무료로 이루어집니다. 이 "
"때문에 특정 사용자가 리소스를 장기간 점유하는 문제를 해결하기에 어려움이 있습"
"니다. 따라서 사용자 여러분들의 배려가 필요합니다."
msgstr ""

#: src/users.md:22
msgid "학기 중 차출"
msgstr ""

#: src/users.md:24
msgid ""
"학기 중에 ferrari 서버의 일부 또는 전체가 수업 활용을 위해 차출될 수 있습니"
"다. 이 경우 MiG (Multi-Instance GPU) 설정이 활성화되어 1개의 A100 GPU가 최대 "
"7개로 쪼개어 사용될 수 있습니다. 바쿠스는 학부 구성원들의 사용 형태를 지속적"
"으로 모니터링하며, 이에 따라 MiG의 구성 및 개수가 조정될 수 있습니다. 방학 중"
"에는 모두 기존 A100으로 합쳐져서 운용됩니다. 학기 중 리소스 차출 여부 및 규모"
"는 리소스 쿼터 요청 구글 폼 페이지에서 확인할 수 있습니다."
msgstr ""

#: src/kubectl.md:3
msgid "kubectl 설치"
msgstr ""

#: src/kubectl.md:5
msgid ""
"SNUCSE GPU 서비스는 싱글 노드 Kubernetes를 활용합니다. 따라서 서버에 접근하"
"기 위해서는 `kubectl` 커맨드라인 툴이 필요합니다. 아래 링크를 참고하여 각자"
"의 로컬 환경에 맞게 `kubectl`을 설치해주시기 바랍니다."
msgstr ""

#: src/kubectl.md:7
msgid "<https://kubernetes.io/docs/tasks/tools/#kubectl>"
msgstr ""

#: src/kubectl.md:9
msgid "클러스터 등록"
msgstr ""

#: src/kubectl.md:11
msgid "`kubectl`을 통해서 서버의 엔트리포인트와 인증서를 등록해야합니다."
msgstr ""

#: src/kubectl.md:13
msgid "엔트리포인트"
msgstr ""

#: src/kubectl.md:13
msgid "인증서"
msgstr ""

#: src/kubectl.md:15
msgid "https://147.46.15.75:6443"
msgstr ""

#: src/kubectl.md:15
msgid "[ferrari.crt](./materials/ferrari.crt)"
msgstr ""

#: src/kubectl.md:16
msgid "https://147.46.92.213:6443"
msgstr ""

#: src/kubectl.md:16
msgid "[bentley.crt](./materials/bentley.crt)"
msgstr ""

#: src/kubectl.md:18
msgid ""
"해당하는 인증서를 적절한 경로에 다운로드한 후 (e.g. `~/.kube/`) 예시와 같은 "
"명령어를 통해 클러스터를 등록합니다. 클러스터를 원하는 이름으로 붙일 수 있습"
"니다. (e.g. `bentley`)"
msgstr ""

#: src/kubectl.md:19
msgid ""
"```sh\n"
"# bentley 서버 등록 예시, 인증서 경로: ~/.kube/bentley.crt\n"
"$ kubectl config set-cluster bentley \\\n"
"  --server=https://147.46.92.213:6443 \\\n"
"  --certificate-authority=bentley.crt\n"
"```"
msgstr ""

#: src/kubelogin.md:3
msgid "kubelogin 설치"
msgstr ""

#: src/kubelogin.md:5
msgid ""
"SNUCSE GPU 서비스는 SNUCSE ID <https://id.snucse.org/>와 연동되어 운영됩니"
"다. SNUCSE ID 계정을 통해 서버에 접근하려면 `kubelogin`이라는 `kubectl` 플러"
"그인이 필요합니다. 아래 링크를 참고하여 `kubelogin`을 설치해주시기 바랍니다."
msgstr ""

#: src/kubelogin.md:7
msgid "<https://github.com/int128/kubelogin>"
msgstr ""

#: src/kubelogin.md:9
msgid ""
"링크 내 매뉴얼에 따르면 `Homebrew`, `Krew`, `Chocolatey`를 통해 설치할 수 있"
"으며, 해당 패키지 매니저가 없을 시 추가 설치가 필요합니다. 일반적인 리눅스 환"
"경에서는 `Krew`를 통한 설치를 권장합니다. `Krew`의 설치 매뉴얼 링크는 아래와 "
"같습니다."
msgstr ""

#: src/kubelogin.md:11
msgid "<https://krew.sigs.k8s.io/docs/user-guide/setup/install/>"
msgstr ""

#: src/kubelogin.md:13
msgid "유저 등록"
msgstr ""

#: src/kubelogin.md:15
msgid ""
"SNUCSE ID를 서버 접근을 위한 유저로 등록해야 합니다. 명령어는 다음과 같습니"
"다. 유저를 원하는 이름으로 붙일 수 있습니다. (아래 예시에서 `oidc`)"
msgstr ""

#: src/kubelogin.md:17
msgid ""
"```sh\n"
"$ kubectl config set-credentials oidc \\\n"
"  --exec-api-version=client.authentication.k8s.io/v1beta1 \\\n"
"  --exec-command=kubectl \\\n"
"  --exec-arg=oidc-login \\\n"
"  --exec-arg=get-token \\\n"
"  --exec-arg=--oidc-issuer-url=https://id.snucse.org/o \\\n"
"  --exec-arg=--oidc-client-id=kubernetes-oidc \\\n"
"  --exec-arg=--oidc-client-secret=kubernetes-oidc\n"
"```"
msgstr ""

#: src/context.md:3
msgid "컨텍스트 등록"
msgstr ""

#: src/context.md:5
msgid ""
"앞선 과정을 통해 클러스터와 유저가 등록됐으므로 이 둘을 묶어 컨텍스트로 등록"
"합니다. 이때 네임스페이스를 같이 지정해주어야 하는데, SNUCSE ID와 연동하여 특"
"정 유저가 본인의 유저명에 해당하는 네임스페이스에서만 작업하도록 강제합니다. "
"따라서 SNUCSE ID 상 유저명을 네임스페이스로 설정합니다. SNUCSE ID 유저명은 "
"<https://id.snucse.org/>에 로그인하여 확인할 수 있습니다. SNUCSE ID 계정이 없"
"으면 가입을 먼저 해주시기 바랍니다. 이전에 `kubectl config set-credentials`에"
"서 등록한 유저 (e.g. `oidc`)와 혼동하지 않도록 주의합니다."
msgstr ""

#: src/context.md:7
msgid ""
"아래는 클러스터가 `bentley`, 유저가 `oidc`, SNUCSE ID 유저명이 `bacchus`일 "
"때 컨텍스트를 `bentley-oidc`로 등록하는 예시입니다."
msgstr ""

#: src/context.md:9
msgid ""
"```sh\n"
"$ kubectl config set-context bentley-oidc \\\n"
"  --cluster=bentley \\\n"
"  --user=oidc \\\n"
"  --namespace=bacchus\n"
"```"
msgstr ""

#: src/context.md:16
msgid "컨텍스트 변경"
msgstr ""

#: src/context.md:18
msgid ""
"여러 서버들을 컨텍스트로 등록하여 이용할 수 있습니다. 이 경우 다음과 같은 방"
"식으로 컨텍스트를 변경할 수 있습니다."
msgstr ""

#: src/context.md:20
msgid ""
"```sh\n"
"# ferrari-oidc가 컨텍스트로 등록되어 있을 시 가능\n"
"$ kubectl config use-context ferrari-oidc\n"
"```"
msgstr ""

#: src/context.md:25
msgid "테스트"
msgstr ""

#: src/context.md:27
msgid "다음 명령어를 통해 서버 접근 가능 여부를 확인할 수 있습니다."
msgstr ""

#: src/context.md:29
msgid ""
"```sh\n"
"$ kubectl get namespaces\n"
"NAME                     STATUS   AGE\n"
"bacchus-gpu-controller   Active   3d2h\n"
"cert-manager             Active   3d2h\n"
"default                  Active   3d5h\n"
"gpu-operator             Active   3d2h\n"
"k0s-autopilot            Active   3d5h\n"
"kube-node-lease          Active   3d5h\n"
"kube-public              Active   3d5h\n"
"kube-system              Active   3d5h\n"
"openebs                  Active   3d2h\n"
"...\n"
"```"
msgstr ""

#: src/context.md:44
msgid ""
"해당 명령어를 실행할 때 인증을 위해 SNUCSE ID 로그인 창이 켜질 수 있습니다. "
"로그인 후 권한을 승인하면 됩니다."
msgstr ""

#: src/quota.md:3
msgid "부트스트랩 생성"
msgstr ""

#: src/quota.md:5
msgid ""
"서버를 접근할 수 있다고 하더라도 유저에게 리소스 쿼터가 부여되지 않아서 작업"
"을 제출, 실행할 수 없습니다. 리소스 쿼터를 받으려면 먼저 작업할 서버에서 유"
"저 부트스트랩을 작성해야 합니다. SNUCSE ID 유저 이름이 `bacchus`라고 한다면, "
"`ub.yaml`의 양식은 아래와 같습니다."
msgstr ""

#: src/quota.md:7
msgid ""
"```yaml\n"
"# ub.yaml\n"
"apiVersion: bacchus.io/v1\n"
"kind: UserBootstrap\n"
"metadata:\n"
"  name: bacchus\n"
"spec: {}\n"
"```"
msgstr ""

#: src/quota.md:16
msgid "해당 파일을 작성한 후 다음 명령어를 실행합니다."
msgstr ""

#: src/quota.md:18
msgid ""
"```sh\n"
"$ kubectl apply -f ub.yaml\n"
"```"
msgstr ""

#: src/quota.md:22
msgid "본인의 부트스트랩이 생성됐는지를 확인합니다."
msgstr ""

#: src/quota.md:23
msgid ""
"```sh\n"
"$ kubectl get userbootstraps.bacchus.io\n"
"NAME      AGE\n"
"bacchus   4h37m\n"
"```"
msgstr ""

#: src/quota.md:30
msgid "리소스 쿼터 신청"
msgstr ""

#: src/quota.md:32
msgid "리소스 종류는 다음과 같습니다. (ephemeral-storage 추후 제한 예정)"
msgstr ""

#: src/quota.md:33
msgid "cpu"
msgstr ""

#: src/quota.md:34
msgid "memory"
msgstr ""

#: src/quota.md:35
msgid "gpu"
msgstr ""

#: src/quota.md:36
msgid "storage"
msgstr ""

#: src/quota.md:38
msgid "아래 구글 폼을 통해 필요한 리소스 쿼터 요청을 작성하여 제출합니다."
msgstr ""

#: src/quota.md:41
msgid ""
"<https://docs.google.com/forms/d/"
"e/1FAIpQLSeC3KTu0ofDaSUTZEJKsEGjTLMgupENkLxR9aVQ2LanA1Spaw/viewform?"
"usp=sf_link>"
msgstr ""

#: src/quota.md:43
msgid ""
"바쿠스에서 검토 후 승인 또는 거부를 하게 됩니다. 승인될 시 리소스 쿼터가 부여"
"되며 아래 명령어를 통해 확인할 수 있습니다."
msgstr ""

#: src/quota.md:45
msgid ""
"```sh\n"
"$ kubectl get resourcequotas\n"
"NAME      AGE     REQUEST                LIMIT\n"
"bacchus   4h41m   requests.cpu: 0/4, ...\n"
"```"
msgstr ""

#: src/quota.md:51
msgid ""
"리소스 쿼터 변경이 필요할 경우 구글 폼을 통해 다시 신청할 수 있으며, 여러 제"
"출 중 승인된 가장 마지막 제출을 기준으로 리소스 쿼터가 설정됩니다."
msgstr ""

#: src/container.md:3
msgid "YAML 파일 작성"
msgstr ""

#: src/container.md:5
msgid ""
"컨테이너를 실행하기 위해서는 먼저 컨테이너 이미지, 필요한 자원 등을 기술한 "
"YAML 파일을 작성해야 합니다. CPU와 메모리 자원은 필수로 요청해야 하며 자원 할"
"당량 초과 시 실행되지 않습니다. 다음은 nginx를 실행하는 `nginx-pod.yaml` 파"
"일 예시입니다."
msgstr ""

#: src/container.md:7
msgid ""
"```yaml\n"
"# nginx-pod.yaml\n"
"apiVersion: v1\n"
"kind: Pod\n"
"metadata:\n"
"  name: nginx-pod\n"
"spec:\n"
"  restartPolicy: Never\n"
"  containers:\n"
"  - name: nginx-container\n"
"    image: \"nginx:latest\"\n"
"    command: [\"echo\"]\n"
"    args: [\"Hello, world!\"]\n"
"    resources:\n"
"      limits:\n"
"        cpu: 2\n"
"        memory: \"1Gi\"\n"
"```"
msgstr ""

#: src/container.md:26
msgid ""
"위 예시는 Pod을 기술한 것으로 `nginx:latest` 이미지를 pull하여 `echo "
"\"Hello, world!\"` 명령어를 수행한 후 종료됩니다. Pod 뿐만 아니라 "
"Deployment, StatefulSet, Job 등 다양한 Kubernetes 워크로드들을 모두 작성하여 "
"실행할 수 있습니다. 자세한 건 사항은 <https://kubernetes.io/docs/concepts/"
"workloads/>를 참고하시기 바랍니다."
msgstr ""

#: src/container.md:28
msgid ""
"주의하실 점은, 기본적으로 모든 유저들에 대해서 Resource Quota가 적용되어 있"
"기 때문에, 요청할 리소스를 정확히 기술해주셔야 합니다. Request와 Limit이 모"
"두 Quota로 제한이 되어 있기 때문에, 위 예시처럼 `limits`만 적어주거나, "
"`requests`와 `limits`를 둘 다 적어주셔야 합니다. Quota에 대한 내용은 [이 문"
"서](./quota.md)를 확인해주시길 바랍니다."
msgstr ""

#: src/container.md:30
msgid "실행 및 확인"
msgstr ""

#: src/container.md:32
msgid ""
"`kubectl apply`를 통해 해당 워크로드를 실행할 수 있습니다. 결과는 `kubectl "
"logs`를 통해 얻을 수 있으며 워크로드의 상태는 `kubectl describe`로 확인할 수 "
"있습니다. 실행이 끝난 워크로드는 `kubectl delete`를 통해 삭제할 수 있습니다."
msgstr ""

#: src/container.md:34
msgid ""
"```sh\n"
"$ kubectl apply -f nginx-pod.yaml\n"
"pod/nginx-pod created\n"
"$ kubectl logs nginx-pod\n"
"Hello, world!\n"
"$ kubectl describe pods nginx-pod\n"
"...\n"
"$ kubectl delete pods nginx-pod\n"
"pod \"nginx-pod\" deleted\n"
"```"
msgstr ""

#: src/container.md:47
msgid "실행 중인 컨테이너를 아래와 같은 명령어로 접속할 수 있습니다."
msgstr ""

#: src/container.md:49
msgid ""
"```sh\n"
"$ kubectl exec nginx-pod -it -- /bin/sh\n"
"```"
msgstr ""

#: src/container.md:53
msgid ""
"하지만 이를 악용하여, **GPU 자원을 할당한 채 무한 루프를 명령어로 제출한 후 "
"컨테이너에 직접 접속해서 코딩 및 실험을 해서는 안됩니다.** GPU 등의 자원을 제"
"대로 사용하지 않고 독점할 수 있기 때문입니다. 해당 행위는 절대 금물이며 바쿠"
"스는 지속적으로 모니터링을 하여 이를 단속합니다. **Jupyter Notebook와 같은 서"
"버를 띄워두고 port-forwarding을 통해 접속하는 것 역시 금지입니다.** 파이썬 스"
"크립트로 변환 후 제출하는 방식으로 부탁드립니다."
msgstr ""

#: src/container.md:55
msgid ""
"다만, GPU 자원 없이 소수의 vCPU를 할당하여 퍼시스턴트 볼륨을 구성한 후 Pod을 "
"삭제하는 등의 극히 예외적인 경우는 어쩔 수 없는 부분입니다. 자유로운 사용을 "
"위해 많은 기능들을 자유롭게 열어두었으니 여러분의 양심에 맡깁니다. 바람직한 "
"사용법은 워크플로우 예시 부분에서 확인할 수 있습니다."
msgstr ""

#: src/volume.md:3
msgid ""
"컨테이너 내부 스토리지에 쓴 데이터, 로그 파일 등은 ephemeral-storage에 저장됩"
"니다. 이 임시 스토리지는 컨테이너 삭제 시 같이 소멸되므로 데이터셋이나 실행 "
"결과 등을 저장하기에는 부적합합니다. 따라서 SNUCSE GPU 서비스는 ZFS 기반의 퍼"
"시스턴트 볼륨을 추가로 제공합니다. 여러분은 퍼시스턴트 볼륨 클레임을 통해서 "
"이 퍼시스턴트 볼륨의 일부를 사용할수 있습니다. 다음 예시 `nginx-pvc.yaml`는 "
"30GiB의 퍼시스턴트 볼륨 클레임을 생성하는 예시입니다."
msgstr ""

#: src/volume.md:5
msgid ""
"```yaml\n"
"# nginx-pvc.yaml\n"
"kind: PersistentVolumeClaim\n"
"apiVersion: v1\n"
"metadata:\n"
"  name: nginx-pvc\n"
"spec:\n"
"  accessModes:\n"
"    - ReadWriteOnce\n"
"  resources:\n"
"    requests:\n"
"      storage: 30Gi\n"
"```"
msgstr ""

#: src/volume.md:19
msgid ""
"```sh\n"
"$ kubectl apply -f nginx-pvc.yaml\n"
"persistentvolumeclaim/nvinx-pvc created\n"
"```"
msgstr ""

#: src/volume.md:24
msgid ""
"아래는 생성한 퍼시스턴트 볼륨 클레임을 통해 볼륨을 `/dataset`에 마운트하는 예"
"시입니다."
msgstr ""

#: src/volume.md:26
msgid ""
"```yaml\n"
"# nginx-pod.yaml\n"
"apiVersion: v1\n"
"kind: Pod\n"
"metadata:\n"
"  name: nginx-pod\n"
"spec:\n"
"  restartPolicy: Never\n"
"  containers:\n"
"  - name: nginx-container\n"
"    image: \"nginx:latest\"\n"
"    command: [\"echo\"]\n"
"    args: [\"Hello, world!\"]\n"
"    resources:\n"
"      requests:\n"
"        cpu: 2\n"
"        memory: \"1Gi\"\n"
"    volumeMounts:\n"
"    - mountPath: \"/dataset\"\n"
"      name: nginx-pv\n"
"  volumes:\n"
"  - name: nginx-pv\n"
"    persistentVolumeClaim:\n"
"      claimName: nginx-pvc\n"
"```"
msgstr ""

#: src/volume.md:52
msgid ""
"`/dataset` 경로에 데이터셋 및 결과를 저장하면 컨테이너 삭제 후에도 데이터가 "
"보존됩니다."
msgstr ""

#: src/registry.md:3
msgid ""
"사용하실 개인 이미지 레지스트리가 없으신 유저분들을 위해서 Bacchus는 레지스트"
"리를 각 GPU 노드에서 제공합니다."
msgstr ""

#: src/registry.md:7
msgid ""
"현재로서는 만드실 수 있는 Project의 개수를 제한하고 있지는 않습니다. 하지만 "
"다른 이용자들도 함께 이용하는 서비스이므로 **한 유저 당 1개의 Project만 만들"
"어서 사용하시길 바랍니다.** 각 Project는 기본적으로 30GB의 스토리지 Quota를 "
"가지고 있습니다."
msgstr ""

#: src/registry.md:9
msgid ""
"만약 어떤 유저가 Project를 무분별하게 만들어서 다른 유저들이 스토리지 공간이 "
"부족해지는 경우가 생기게 된다면, 그 유저의 Project들은 예고 없이 삭제될 수 있"
"고, 향후 GPU 서비스의 이용이 제한될 예정입니다."
msgstr ""

#: src/registry.md:11
msgid "제공 중인 레지스트리"
msgstr ""

#: src/registry.md:13
msgid "현재 제공되고 있는 레지스트리는 다음과 같습니다."
msgstr ""

#: src/registry.md:15
msgid "[ferrari](https://registry.ferrari.snucse.org:30443/)"
msgstr ""

#: src/registry.md:16
msgid "[bentley](https://registry.bentley.snucse.org:30443/)"
msgstr ""

#: src/registry.md:18
msgid "이용 방법"
msgstr ""

#: src/registry.md:20
msgid "프로젝트 생성"
msgstr ""

#: src/registry.md:22
msgid ""
"이용하고 싶은 레지스트리의 URL에 접속하고, `LOGIN VIA OIDC PROVIDER` 버튼을 "
"통해서 로그인합니다."
msgstr ""

#: src/registry.md:23
msgid ""
"좌측의 `Projects` 탭으로 이동하고, `New Project` 버튼을 눌러서 새로운 프로젝"
"트를 생성합니다."
msgstr ""

#: src/registry.md:25
msgid "레지스트리 로그인"
msgstr ""

#: src/registry.md:27
msgid ""
"기본적으로 다른 이미지 레지스트리를 사용하는 방법과 같습니다. 이 경우 CLI에"
"서 로그인을 해야하는데, 이 때 사용되는 Credential은 다음과 같습니다."
msgstr ""

#: src/registry.md:29
msgid "`Username`: ID username"
msgstr ""

#: src/registry.md:30
msgid "`Password`: CLI secret"
msgstr ""

#: src/registry.md:32
msgid "`CLI secret`을 얻기 위해서는 다음을 따릅니다."
msgstr ""

#: src/registry.md:34
msgid "우측 상단의 버튼에서 `User Profile`을 누릅니다."
msgstr ""

#: src/registry.md:35
msgid ""
"CLI Secret 란의 오른쪽에 있는 Copy 버튼을 눌러서 클립보드에 시크릿을 복사합니"
"다."
msgstr ""

#: src/registry.md:37
msgid "이후, CLI에서 다음과 같이 로그인합니다."
msgstr ""

#: src/registry.md:39
msgid ""
"```sh\n"
"# 사용할 레지스트리에 따라서 URL은 바뀌게 됩니다. 여기서는 ferrari의 레지스트"
"리를 예시로 들겠습니다.\n"
"docker login https://registry.ferrari.snucse.org:30443/\n"
"\n"
"# 이후 prompt에서 물어보는 username과 password를 입력합니다.\n"
"```"
msgstr ""

#: src/example.md:3
msgid ""
"모델 사이즈가 263.9GiB인 Llama-2-70b 모델을 80GB HBM2E A100이 8장 있는 "
"ferrari 서버에 올리는 예시를 들어겠습니다."
msgstr ""

#: src/example.md:5
msgid "퍼시스턴트 볼륨 클레임 생성"
msgstr ""

#: src/example.md:7
msgid ""
"먼저 충분한 자원 할당량이 있는지 확인합니다. 아래의 경우는 테스트를 위해 할당"
"량을 매우 크게 잡은 상태입니다."
msgstr ""

#: src/example.md:9
msgid ""
"```sh\n"
"$ kubectl get resourcequotas\n"
"NAME      AGE   REQUEST\n"
"whnbaek   19h   requests.cpu: 0/256, requests.memory: 0/1Ti, requests.nvidia."
"com/gpu: 0/8, requests.storage: 0/1000Gi\n"
"```"
msgstr ""

#: src/example.md:15
msgid ""
"모델이 들어가기에 충분하도록 300GB의 퍼시스턴트 볼륨 클레임, `llama-2-70b-"
"pvc.yaml`을 먼저 생성하겠습니다."
msgstr ""

#: src/example.md:17
msgid ""
"```yaml\n"
"# llama-2-70b-pvc.yaml\n"
"kind: PersistentVolumeClaim\n"
"apiVersion: v1\n"
"metadata:\n"
"  name: llama-2-70b-pvc\n"
"spec:\n"
"  accessModes:\n"
"    - ReadWriteOnce\n"
"  resources:\n"
"    requests:\n"
"      storage: 300Gi\n"
"```"
msgstr ""

#: src/example.md:31
msgid ""
"```sh\n"
"$ kubectl apply -f llama-2-70b-pvc.yaml\n"
"persistentvolumeclaim/llama-2-70b-pvc created\n"
"```"
msgstr ""

#: src/example.md:36
msgid "이미지 빌드"
msgstr ""

#: src/example.md:38
msgid ""
"Llama 2는 Pytorch 및 CUDA 환경을 사용합니다. 이들이 미리 세팅된 `nvcr.io/"
"nvidia/pytorch:23.06-py3` 이미지를 베이스로 사용하겠습니다. 이미지는 어느 곳"
"에서 어떠한 방식으로 빌드해도 상관이 없지만 예시에서는 로컬에서 Dockerfile을 "
"작성하여 빌드했습니다. 아래는 빌드에 사용된 Dockerfile입니다."
msgstr ""

#: src/example.md:40
msgid ""
"```dockerfile\n"
"# Dockerfile\n"
"FROM nvcr.io/nvidia/pytorch:23.06-py3\n"
"\n"
"RUN apt-get update && apt-get install -y wget git\n"
"\n"
"WORKDIR /\n"
"RUN git clone https://github.com/facebookresearch/llama.git\n"
"RUN cd llama && pip install -e .\n"
"```"
msgstr ""

#: src/example.md:51
msgid ""
"해당 빌드는 로컬에 보관할 수도 있고, 제공한 Harbor 레지스트리에 보관할 수도 "
"있습니다. 제공한 레지스트리를 이용할 경우 서버의 로컬 스토리지에 이미지가 저"
"장되므로 컨테이너 실행 시 이미지를 고속으로 pull할 수 있습니다. Harbor에 올려"
"서 사용하는 시나리오를 예로 들겠습니다."
msgstr ""

#: src/example.md:53
msgid ""
"```sh\n"
"# https://registry.ferrari.snucse.org:30443 에 bacchus라는 project가 있다고 "
"가정\n"
"$ docker build -t registry.ferrari.snucse.org:30443/bacchus/llama:latest - < "
"Dockerfile\n"
"$ docker push registry.ferrari.snucse.org:30443/bacchus/llama:latest\n"
"```"
msgstr ""

#: src/example.md:59
msgid "모델 파라미터 다운로드"
msgstr ""

#: src/example.md:61
msgid ""
"```yaml\n"
"# llama-2-70b-download.yaml\n"
"apiVersion: v1\n"
"kind: Pod\n"
"metadata:\n"
"  name: llama-2-70b-download\n"
"spec:\n"
"  restartPolicy: Never\n"
"\n"
"  containers:\n"
"  - name: llama-2-70b-container\n"
"    image: \"registry.ferrari.snucse.org:30443/bacchus/llama:latest\"\n"
"    command: [\"/bin/bash\"]\n"
"    args: [\"-c\", \"cd /data; echo \\"
"\"$URL_FROM_EMAIL\\n$MODELS_TO_DOWNLOAD\\\" | /llama/download.sh;\"]\n"
"    resources:\n"
"      limits:\n"
"        cpu: 4\n"
"        memory: \"1Gi\"\n"
"    volumeMounts:\n"
"    - mountPath: \"/data\"\n"
"      name: llama-2-70b-pv\n"
"    env:\n"
"    - name: URL_FROM_EMAIL\n"
"      value: \"the URL from email\"\n"
"    - name: MODELS_TO_DOWNLOAD\n"
"      value: \"70B\"\n"
"  volumes:\n"
"  - name: llama-2-70b-pv\n"
"    persistentVolumeClaim:\n"
"      claimName: llama-2-70b-pvc\n"
"```"
msgstr ""

#: src/example.md:93
msgid ""
"위 예시에서 `URL_FROM_EMAIL`을 채워넣은 후 실행하여 퍼시스턴트 볼륨에 모델 파"
"라미터를 다운로드합니다."
msgstr ""

#: src/example.md:95
msgid ""
"```sh\n"
"$ kubectl apply -f llama-2-70b-download.yaml\n"
"pod/llama-2-70b-download created\n"
"```"
msgstr ""

#: src/example.md:100
msgid ""
"다운로드가 완료되면 완료된 pod을 지우고 실제 실험 컨테이너를 실행합니다."
msgstr ""

#: src/example.md:102
msgid ""
"```sh\n"
"$ kubectl delete pods llama-2-70b-download\n"
"pod \"llama-2-70b-download\" deleted\n"
"```"
msgstr ""

#: src/example.md:107
msgid ""
"위와 같이 데이터셋 및 모델 weight를 준비할 때 소수의 CPU만 할당하여 준비하시"
"기 바랍니다. 스크립트를 한번에 짜서 준비하는 게 어려울 경우"
msgstr ""

#: src/example.md:110
msgid ""
"```yaml\n"
"    command: [ \"/bin/bash\", \"-c\", \"--\" ]\n"
"    args: [ \"while true; do sleep 30; done;\" ]\n"
"```"
msgstr ""

#: src/example.md:115
msgid ""
"와 같이 무한루프를 제출하고 `kubectl exec`으로 접속하여 퍼시스턴트 볼륨 내 데"
"이터를 준비할 수 있습니다. 세팅이 끝나면 반드시 해당 pod을 삭제해주시기 바랍"
"니다."
msgstr ""

#: src/example.md:118
msgid "테스트 실행"
msgstr ""

#: src/example.md:120
msgid ""
"```yaml\n"
"# llama-2-70b-run.yaml\n"
"apiVersion: v1\n"
"kind: Pod\n"
"metadata:\n"
"  name: llama-2-70b-run\n"
"spec:\n"
"  restartPolicy: Never\n"
"\n"
"  containers:\n"
"  - name: llama-2-70b-container\n"
"    image: \"registry.ferrari.snucse.org:30443/bacchus/llama:latest\"\n"
"    command: [\"torchrun\"]\n"
"    args: [\"--nproc_per_node\", \"8\", \"/llama/example_text_completion."
"py\", \\\n"
"        \"--ckpt_dir\", \"llama-2-70b\", \"--tokenizer_path\", \"tokenizer."
"model\", \\\n"
"        \"--max_seq_len 128\", \"--max_batch_size\", \"4\"]\n"
"    resources:\n"
"      limits:\n"
"        cpu: 256\n"
"        memory: \"1000Gi\"\n"
"        nvidia.com/gpu: 8\n"
"    volumeMounts:\n"
"    - mountPath: \"/data\"\n"
"      name: llama-2-70b-pv\n"
"  volumes:\n"
"  - name: llama-2-70b-pv\n"
"    persistentVolumeClaim:\n"
"      claimName: llama-2-70b-pvc\n"
"```"
msgstr ""

#: src/example.md:150
msgid ""
"```sh\n"
"$ kubectl apply -f llama-2-70b-run.yaml\n"
"pod/llama-2-70b-run created\n"
"```"
msgstr ""

#: src/example.md:155
msgid "기타"
msgstr ""

#: src/example.md:157
msgid ""
"소스코드를 수정하거나 패키지를 추가 설치해야 하는 등의 경우 이미지를 다시 빌"
"드한 후 레지스트리에 push해야 합니다. 이미지 빌드 시에는 Dockerfile을 작성하"
"거나 `docker commit`을 이용하면 됩니다. 연구 특성상 소스코드 수정 후 실행을 "
"자주 반복해야 하는 경우가 많습니다. 이때 이미지 레이어가 캐싱되는 것을 고려하"
"지 않은 채 빌드하게 되면 매번 큰 양의 데이터가 네트워크를 통해 전송되게 되므"
"로 수정 후 실행 주기가 길어질 수밖에 없습니다. 이미지 레이어 캐싱을 고려해서 "
"빌드해주시기 바랍니다. 소스코드를 Github에 올린 후 Github Action과 Github "
"Packages를 이용하여 이미지를 자동 빌드하는 방법도 좋습니다. "
msgstr ""

#: src/example.md:159
msgid ""
"퍼시스턴트 볼륨으로 파일을 보내거나 꺼내야 하는 경우 `kubectl cp`를 사용하면 "
"됩니다. (`kubectl cp --help` 참고) 이때 퍼시스턴트 볼륨이 pod과 붙어 있어야 "
"하므로 무한루프를 걸어 소수의 vCPU와 함께 Pod을 띄운 후 데이터를 주고 받으면 "
"됩니다."
msgstr ""

#: src/developers.md:5
msgid "팀장"
msgstr ""

#: src/developers.md:6
msgid "**백우현** / 컴퓨터공학부 17"
msgstr ""

#: src/developers.md:8
msgid "팀원"
msgstr ""

#: src/developers.md:9
msgid "**김무환** / 컴퓨터공학부 17"
msgstr ""

#: src/developers.md:10
msgid "**김민준** / 수 리 과 학 부 23"
msgstr ""

#: src/developers.md:11
msgid "**박재현** / 컴퓨터공학부 16"
msgstr ""

#: src/developers.md:12
msgid "**박종훈** / 컴퓨터공학부 15"
msgstr ""

#: src/developers.md:13
msgid "**박찬우** / 경   영  학   과 17"
msgstr ""

#: src/developers.md:14
msgid "**서지민** / 컴퓨터공학부 20"
msgstr ""

#: src/developers.md:15
msgid "**성용운** / 컴퓨터공학부 17"
msgstr ""

#: src/developers.md:16
msgid "**오평석** / 컴퓨터공학부 13"
msgstr ""

#: src/developers.md:17
msgid "**오하나** / 자유전공학부 19"
msgstr ""

#: src/developers.md:18
msgid "**윤지학** / 컴퓨터공학부 16"
msgstr ""

#: src/developers.md:19
msgid "**이준혁** / 컴퓨터공학부 17"
msgstr ""

#: src/developers.md:20
msgid "**최원우** / 컴퓨터공학부 16"
msgstr ""

#: src/developers.md:22
msgid "도움 주신 분들"
msgstr ""

#: src/developers.md:23
msgid "**이재욱** 교수님"
msgstr ""

#: src/developers.md:24
msgid "**전병곤** 교수님"
msgstr ""
