
msgid ""
msgstr ""
"Project-Id-Version: SNUCSE GPU 서비스 매뉴얼\n"
"POT-Creation-Date: \n"
"PO-Revision-Date: \n"
"Last-Translator: \n"
"Language-Team: \n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Language: ko\n"
"Plural-Forms: nplurals=1; plural=0;\n"

#: src/SUMMARY.md:3
msgid "SNUCSE GPU 서비스"
msgstr ""

#: src/SUMMARY.md:7
msgid "운영 안내"
msgstr ""

#: src/SUMMARY.md:9
msgid "서버 목록"
msgstr ""

#: src/SUMMARY.md:10
msgid "사용자 안내"
msgstr ""

#: src/SUMMARY.md:11
msgid "자원 회수"
msgstr ""

#: src/SUMMARY.md:13
msgid "서버 접근 방법"
msgstr ""

#: src/SUMMARY.md:15
msgid "kubectl 설치 및 설정"
msgstr ""

#: src/SUMMARY.md:16
msgid "kubelogin 설치 및 설정"
msgstr ""

#: src/SUMMARY.md:17
msgid "컨텍스트 설정 및 테스트"
msgstr ""

#: src/SUMMARY.md:19
msgid "서버 이용 방법"
msgstr ""

#: src/SUMMARY.md:21
msgid "리소스 쿼터 설정"
msgstr ""

#: src/SUMMARY.md:22
msgid "컨테이너 실행"
msgstr ""

#: src/SUMMARY.md:23
msgid "퍼시스턴트 볼륨 설정"
msgstr ""

#: src/SUMMARY.md:24
msgid "이미지 레지스트리 이용"
msgstr ""

#: src/SUMMARY.md:25
msgid "워크플로우 예시"
msgstr ""

#: src/SUMMARY.md:29
msgid "개발팀"
msgstr ""

#: src/introduction.md:1
msgid "# SNUCSE GPU 서비스"
msgstr ""

#: src/introduction.md:3
#: src/developers.md:3
msgid ""
"<p align=center><img height=83 src=\"materials/bacchus.png\"><img height=83 "
"src=\"materials/glass.png\"></p>"
msgstr ""

#: src/introduction.md:5
msgid "안녕하세요, 여러분과 함께하는 서울대학교 컴퓨터공학부 서버 관리자 모임 바쿠스입니다."
msgstr ""

#: src/introduction.md:7
msgid ""
"바쿠스에서는 컴퓨터공학부 구성원들에게 GPU 서버를 무료로 제공하고 있습니다. **A100 GPU** 서버를 이용하실 분들은 이 매뉴얼을 "
"읽어주시기 바랍니다."
msgstr ""

#: src/introduction.md:9
msgid "기타 문의사항은 <contact@bacchus.snucse.org>로 보내주시기 바랍니다. 감사합니다."
msgstr ""

#: src/servers.md:1
msgid "# 서버 목록"
msgstr ""

#: src/servers.md:3
msgid "## 이용 가능 서버"
msgstr ""

#: src/servers.md:5
msgid ""
"| 서버명                  | GPU                       | vCPU | 메모리  | GPU P2P  "
"| 스토리지 |\n"
"|:---------------------- |:------------------------- |:---- |:------ "
"|:-------- |:------- |\n"
"| ferrari<br/>(HGX A100) | 8 x A100<br/>(80GB HBM2E) | 256  | 1024GB | "
"NVSwitch | 7.68TB  |\n"
"| bentley<br/>(DGX A100) | 8 x A100<br/>(40GB HBM2)  | 256  | 1024GB | "
"NVSwitch | 15.36TB |"
msgstr ""

#: src/servers.md:10
msgid "## 도입 예정 서버"
msgstr ""

#: src/servers.md:12
msgid ""
"| 서버명                  | GPU                       | vCPU | 메모리  | GPU P2P  "
"| 스토리지 |\n"
"|:---------------------- |:------------------------- |:---- |:------ "
"|:-------- |:------- |\n"
"| ford<br/>(HGX A100)    | 4 x A100<br/>(80GB HBM2E) | 64   | 768GB  | "
"NVLink   | 7.68TB  |"
msgstr ""

#: src/servers.md:16
msgid "## 주의"
msgstr ""

#: src/servers.md:18
msgid "현재 기술적인 문제로 GPUDirect RDMA 및 GPUDirect Storage가 지원되지 않습니다. 추후 지원될 예정입니다."
msgstr ""

#: src/users.md:1
msgid "# 사용자 안내"
msgstr ""

#: src/users.md:3
msgid "## 대상"
msgstr ""

#: src/users.md:5
msgid ""
"- 학부생\n"
"  - 컴퓨터공학부 주전공생\n"
"  - 자유전공학부 (컴퓨터공학 주전공) 학생\n"
"  - 컴퓨터공학부 복수/부전공생\n"
"- 대학원생\n"
"  - 컴퓨터공학부 대학원생\n"
"  - 협동과정 인공지능 소속 중 지도교수가 컴퓨터공학부 소속인 대학원생"
msgstr ""

#: src/users.md:13
msgid ""
"ferrari 서버는 학부생, 대학원생 모두 이용할 수 있습니다.\n"
"bentley 서버는 대학원생만 이용할 수 있습니다.\n"
"학부생은 [SNUCSE ID](https://id.snucse.org)에서 학부생 그룹에, 대학원생은 대학원생 그룹에 가입해야 이용 "
"가능합니다.\n"
"그룹 가입 신청 시 승인 관련은 학부 행정실로 문의 바랍니다."
msgstr ""

#: src/users.md:18
#: src/container.md:45
#: src/registry.md:5
msgid "## 주의사항"
msgstr ""

#: src/users.md:20
msgid ""
"모든 서버는 **연구 목적**으로만 사용 가능합니다. 바쿠스는 서버를 항시 모니터링하고 있으며, 연구 목적 이외의 사용이 적발될 경우 "
"서비스 이용에 불이익이 있을 수 있습니다."
msgstr ""

#: src/users.md:22
msgid ""
"SNUCSE GPU 서비스는 모두 무료로 제공됩니다. 이 때문에 특정 사용자가 리소스를 장기간 점유하는 문제를 해결하기에 어려움이 "
"있습니다. A100 GPU의 리소스가 많지 않으니 A100이 필요한 경우에만 사용을 해주시기 바랍니다. 과도한 GPU 점유로 인하여 다른 "
"유저들이 신청한 GPU를 제대로 사용하지 못하게 되는 경우, 워크로드는 언제든지 바쿠스에 의해서 종료될 수 있습니다. 사용자 여러분들의 "
"배려를 부탁드립니다."
msgstr ""

#: src/users.md:24
msgid "## 학기 중 차출"
msgstr ""

#: src/users.md:26
msgid ""
"학기 중에 ferrari 서버의 일부 또는 전체가 수업 활용을 위해 차출될 수 있습니다. 학기 중 리소스 차출 여부 및 규모는 리소스 "
"쿼터 요청 구글 폼 페이지에서 확인할 수 있습니다."
msgstr ""

#: src/resource_reclaim.md:1
msgid "# 주기적 자원 회수"
msgstr ""

#: src/resource_reclaim.md:3
msgid "## 회수 주기"
msgstr ""

#: src/resource_reclaim.md:5
msgid ""
"적은 자원을 많은 유저가 나누어 쓰고 있기 때문에, 바쿠스는 주기적으로 신청받았던 자원들을 강제 회수합니다. 회수 주기는 다음과 같습니다."
msgstr ""

#: src/resource_reclaim.md:7
msgid ""
"- 봄학기 시작 전\n"
"- 여름방학 시작 전\n"
"- 가을학기 시작 전\n"
"- 겨울방학 시작 전"
msgstr ""

#: src/resource_reclaim.md:12
msgid ""
"강제 회수 전, 신청 양식에 기입하셨던 메일 주소로 메일을 보내게 됩니다. 메일을 받으셨다면, 저장된 자료를 미리 백업하시거나, 계속 "
"사용을 아래 안내에 따라서 신청해주시길 바랍니다. 정확한 회수 일정은 받으신 메일 본문을 참고해주세요. 회수 주기를 확인하지 않고 유실된 "
"내용에 대해서는 바쿠스는 책임지지 않습니다."
msgstr ""

#: src/resource_reclaim.md:14
msgid "## 계속 사용 희망"
msgstr ""

#: src/resource_reclaim.md:16
msgid ""
"위 회수 주기에 자원 회수를 원하지 않으시는 분들은 회수 안내 메일 본문에 "
"[contact@bacchus.snucse.org](mailto:contact@bacchus.snucse.org) 참조를 반드시 포함하여 "
"계속 사용을 희망한다는 의사를 답장으로 밝혀주시기 바랍니다. 새로운 사용 신청자들과 다음 학기 자원 배분 계획에 따라 계속 사용 신청은 "
"반려될 수도 있으니 참고해주시길 바랍니다."
msgstr ""

#: src/kubectl.md:1
msgid "# kubectl 설치 및 설정"
msgstr ""

#: src/kubectl.md:3
msgid "## kubectl 설치"
msgstr ""

#: src/kubectl.md:5
msgid ""
"SNUCSE GPU 서비스는 싱글 노드 Kubernetes를 활용합니다. 따라서 서버에 접근하기 위해서는 `kubectl` 커맨드라인 "
"툴이 필요합니다. 아래 링크를 참고하여 각자의 로컬 환경에 맞게 `kubectl`을 설치해주시기 바랍니다."
msgstr ""

#: src/kubectl.md:7
msgid "<https://kubernetes.io/docs/tasks/tools/#kubectl>"
msgstr ""

#: src/kubectl.md:9
msgid "## 클러스터 등록"
msgstr ""

#: src/kubectl.md:11
msgid "`kubectl`을 통해서 서버의 엔트리포인트와 인증서를 등록해야합니다."
msgstr ""

#: src/kubectl.md:13
msgid ""
"| 서버명   | 엔트리포인트                 | 인증서                                  |\n"
"|:------- |:-------------------------- "
"|:-------------------------------------- |\n"
"| ferrari | https://147.46.15.75:6443  | "
"[ferrari.crt](./materials/ferrari.crt) | \n"
"| bentley | https://147.46.92.213:6443 | "
"[bentley.crt](./materials/bentley.crt) |"
msgstr ""

#: src/kubectl.md:18
msgid ""
"해당하는 인증서를 적절한 경로에 다운로드한 후 (e.g. `~/.kube/`) 예시와 같은 명령어를 통해 클러스터를 등록합니다. "
"클러스터를 원하는 이름으로 붙일 수 있습니다. (e.g. `bentley`)"
msgstr ""

#: src/kubectl.md:19
msgid ""
"```sh\n"
"# bentley 서버 등록 예시, 인증서 경로: ~/.kube/bentley.crt\n"
"$ kubectl config set-cluster bentley \\\n"
"  --server=https://147.46.92.213:6443 \\\n"
"  --certificate-authority=bentley.crt\n"
"```"
msgstr ""

#: src/kubelogin.md:1
msgid "# kubelogin 설치 및 설정"
msgstr ""

#: src/kubelogin.md:3
msgid "## kubelogin 설치"
msgstr ""

#: src/kubelogin.md:5
msgid ""
"SNUCSE GPU 서비스는 SNUCSE ID <https://id.snucse.org/>와 연동되어 운영됩니다. SNUCSE ID "
"계정을 통해 서버에 접근하려면 `kubelogin`이라는 `kubectl` 플러그인이 필요합니다. 아래 링크를 참고하여 "
"`kubelogin`을 설치해주시기 바랍니다."
msgstr ""

#: src/kubelogin.md:7
msgid "<https://github.com/int128/kubelogin>"
msgstr ""

#: src/kubelogin.md:9
msgid ""
"링크 내 매뉴얼에 따르면 `Homebrew`, `Krew`, `Chocolatey`를 통해 설치할 수 있으며, 해당 패키지 매니저가 없을 "
"시 추가 설치가 필요합니다. 일반적인 리눅스 환경에서는 `Krew`를 통한 설치를 권장합니다. `Krew`의 설치 매뉴얼 링크는 아래와 "
"같습니다."
msgstr ""

#: src/kubelogin.md:11
msgid "<https://krew.sigs.k8s.io/docs/user-guide/setup/install/>"
msgstr ""

#: src/kubelogin.md:13
msgid "## 유저 등록"
msgstr ""

#: src/kubelogin.md:15
msgid ""
"SNUCSE ID를 서버 접근을 위한 유저로 등록해야 합니다. 명령어는 다음과 같습니다. 유저를 원하는 이름으로 붙일 수 있습니다. "
"(e.g. `oidc`)"
msgstr ""

#: src/kubelogin.md:17
msgid ""
"```sh\n"
"$ kubectl config set-credentials oidc \\\n"
"  --exec-api-version=client.authentication.k8s.io/v1beta1 \\\n"
"  --exec-command=kubectl \\\n"
"  --exec-arg=oidc-login \\\n"
"  --exec-arg=get-token \\\n"
"  --exec-arg=--oidc-issuer-url=https://id.snucse.org/o \\\n"
"  --exec-arg=--oidc-client-id=kubernetes-oidc \\\n"
"  --exec-arg=--oidc-client-secret=kubernetes-oidc\n"
"```"
msgstr ""

#: src/context.md:1
msgid "# 컨텍스트 설정 및 테스트"
msgstr ""

#: src/context.md:3
msgid "## 컨텍스트 등록"
msgstr ""

#: src/context.md:5
msgid ""
"앞선 과정을 통해 클러스터와 유저가 등록됐으므로 이 둘을 묶어 컨텍스트로 등록합니다. 이때 네임스페이스를 같이 지정해주어야 하는데, "
"SNUCSE ID와 연동하여 특정 유저가 본인의 유저명에 해당하는 네임스페이스에서만 작업하도록 강제합니다. 따라서 SNUCSE ID 상 "
"유저명을 네임스페이스로 설정합니다. SNUCSE ID 유저명은 [SNUCSE ID](https://id.snucse.org/)에 "
"로그인하여 확인할 수 있습니다. SNUCSE ID 계정이 없으면 가입을 먼저 해주시기 바랍니다. 이전에 `kubectl config "
"set-credentials`에서 등록한 유저 (e.g. `oidc`)와 혼동하지 않도록 주의합니다."
msgstr ""

#: src/context.md:7
msgid ""
"아래는 클러스터가 `bentley`, 유저가 `oidc`, SNUCSE ID 유저명이 `deadbeef`일 때 컨텍스트를 "
"`bentley-oidc`로 등록하는 예시입니다."
msgstr ""

#: src/context.md:9
msgid ""
"```sh\n"
"$ kubectl config set-context bentley-oidc \\\n"
"  --cluster=bentley \\\n"
"  --user=oidc \\\n"
"  --namespace=deadbeef\n"
"```"
msgstr ""

#: src/context.md:16
msgid "## 컨텍스트 변경"
msgstr ""

#: src/context.md:18
msgid "여러 서버들을 컨텍스트로 등록하여 이용할 수 있습니다. 이 경우 다음과 같은 방식으로 컨텍스트를 변경할 수 있습니다."
msgstr ""

#: src/context.md:20
msgid ""
"```sh\n"
"# ferrari-oidc가 컨텍스트로 등록되어 있을 시 가능\n"
"$ kubectl config use-context ferrari-oidc\n"
"```"
msgstr ""

#: src/context.md:25
msgid "## 테스트"
msgstr ""

#: src/context.md:27
msgid "다음 명령어를 통해 서버 접근 가능 여부를 확인할 수 있습니다."
msgstr ""

#: src/context.md:29
msgid ""
"```sh\n"
"$ kubectl get namespaces\n"
"NAME                     STATUS   AGE\n"
"bacchus-gpu-controller   Active   3d2h\n"
"cert-manager             Active   3d2h\n"
"default                  Active   3d5h\n"
"gpu-operator             Active   3d2h\n"
"k0s-autopilot            Active   3d5h\n"
"kube-node-lease          Active   3d5h\n"
"kube-public              Active   3d5h\n"
"kube-system              Active   3d5h\n"
"openebs                  Active   3d2h\n"
"...\n"
"```"
msgstr ""

#: src/context.md:44
msgid ""
"해당 명령어를 실행할 때 인증을 위해 SNUCSE ID 로그인 창이 켜질 수 있습니다. 로그인 후 권한을 승인하면 됩니다.\n"
"서버 접근 과정에서 SNUCSE ID의 그룹 가입 정보를 확인합니다. ferrari 접근 시 학부생 또는 대학원생 그룹에,\n"
"bentley 접근 시 대학원생 그룹에 가입되어 있어야 합니다. 그룹 가입 정보가 없거나 잘못된 경우 접근이 거부됩니다."
msgstr ""

#: src/quota.md:1
msgid "# 리소스 쿼터 설정"
msgstr ""

#: src/quota.md:3
msgid "## 부트스트랩 생성"
msgstr ""

#: src/quota.md:5
msgid ""
"서버를 접근할 수 있다고 하더라도 유저에게 리소스 쿼터가 부여되지 않아서 작업을 제출, 실행할 수 없습니다. 리소스 쿼터를 받으려면 먼저 "
"작업할 서버에서 유저 부트스트랩을 작성해야 합니다. SNUCSE ID 유저 이름이 `deadbeef`라고 한다면, `ub.yaml`의 "
"양식은 아래와 같습니다."
msgstr ""

#: src/quota.md:7
msgid ""
"```yaml\n"
"# ub.yaml\n"
"apiVersion: bacchus.io/v1\n"
"kind: UserBootstrap\n"
"metadata:\n"
"  name: deadbeef\n"
"spec: {}\n"
"```"
msgstr ""

#: src/quota.md:16
msgid "해당 파일을 작성한 후 다음 명령어를 실행합니다."
msgstr ""

#: src/quota.md:18
msgid ""
"```sh\n"
"$ kubectl apply -f ub.yaml\n"
"```"
msgstr ""

#: src/quota.md:22
msgid "본인의 부트스트랩이 생성됐는지를 확인합니다."
msgstr ""

#: src/quota.md:23
msgid ""
"```sh\n"
"$ kubectl get userbootstraps.bacchus.io\n"
"NAME      AGE\n"
"deadbeef   1m\n"
"```"
msgstr ""

#: src/quota.md:30
msgid "## 리소스 쿼터 신청"
msgstr ""

#: src/quota.md:32
msgid "리소스 종류는 다음과 같습니다."
msgstr ""

#: src/quota.md:33
msgid "- gpu, cpu, memory\n- storage"
msgstr ""

#: src/quota.md:36
msgid ""
"리소스 쿼터는 GPU 개수 단위로 받으며 GPU 1개 당 vCPU 28개, 메모리 112GB가 함께 부여됩니다.\n"
"스토리지 용량은 따로 받습니다."
msgstr ""

#: src/quota.md:39
msgid ""
"[구글 "
"폼](https://docs.google.com/forms/d/e/1FAIpQLSeC3KTu0ofDaSUTZEJKsEGjTLMgupENkLxR9aVQ2LanA1Spaw/viewform?usp=sf_link)을 "
"통해 필요한 리소스 쿼터 요청을 작성하여 제출합니다."
msgstr ""

#: src/quota.md:41
msgid ""
"바쿠스에서 검토 후 승인 또는 거부를 하게 됩니다. 보통 하루 안쪽으로 승인되며, 거부 시에는 이메일로 안내됩니다. 승인될 시 리소스 "
"쿼터가 부여되며 아래 명령어를 통해 확인할 수 있습니다."
msgstr ""

#: src/quota.md:43
msgid ""
"```sh\n"
"$ kubectl get resourcequotas\n"
"NAME      AGE     REQUEST                  LIMIT\n"
"deadbeef  2m      requests.cpu: 0/28, ...\n"
"```"
msgstr ""

#: src/quota.md:49
msgid ""
"리소스 쿼터 변경이 필요할 경우 구글 폼을 통해 다시 신청할 수 있으며, 여러 제출 중 승인된 가장 마지막 제출을 기준으로 리소스 쿼터가 "
"설정됩니다."
msgstr ""

#: src/container.md:1
msgid "# 컨테이너 실행"
msgstr ""

#: src/container.md:3
msgid "## YAML 파일 작성"
msgstr ""

#: src/container.md:5
msgid ""
"컨테이너를 실행하기 위해서는 먼저 컨테이너 이미지, 필요한 자원 등을 기술한 YAML 파일을 작성해야 합니다. CPU와 메모리 자원은 "
"필수로 요청해야 하며 자원 할당량 초과 시 실행되지 않습니다. 다음은 nginx를 실행하는 `nginx-pod.yaml` 파일 예시입니다."
msgstr ""

#: src/container.md:7
msgid ""
"```yaml\n"
"# nginx-pod.yaml\n"
"apiVersion: v1\n"
"kind: Pod\n"
"metadata:\n"
"  name: nginx-pod\n"
"spec:\n"
"  restartPolicy: Never\n"
"  containers:\n"
"  - name: nginx-container\n"
"    image: \"nginx:latest\"\n"
"    command: [\"echo\"]\n"
"    args: [\"Hello, world!\"]\n"
"    resources:\n"
"      limits:\n"
"        cpu: 2\n"
"        memory: \"1Gi\"\n"
"```"
msgstr ""

#: src/container.md:26
msgid ""
"위 예시는 Pod을 기술한 것으로 `nginx:latest` 이미지를 pull하여 `echo \"Hello, world!\"` 명령어를 "
"수행한 후 종료됩니다. Pod 뿐만 아니라 Deployment, StatefulSet, Job 등 다양한 Kubernetes 워크로드들을 "
"모두 작성하여 실행할 수 있습니다. 자세한 건 사항은 [쿠버네티스 워크로드 "
"매뉴얼](https://kubernetes.io/docs/concepts/workloads/)을 참고하시기 바랍니다."
msgstr ""

#: src/container.md:28
msgid ""
"주의하실 점은, 기본적으로 모든 유저들에 대해서 Resource Quota가 적용되어 있기 때문에, 요청할 리소스를 정확히 기술해주셔야 "
"합니다. Request와 Limit이 모두 Quota로 제한이 되어 있기 때문에, 위 예시처럼 `limits`만 적어주거나, "
"`requests`와 `limits`를 둘 다 적어주셔야 합니다. Quota에 대한 내용은 [이 문서](./quota.md)를 "
"확인해주시길 바랍니다."
msgstr ""

#: src/container.md:30
msgid "## 실행 및 확인"
msgstr ""

#: src/container.md:32
msgid ""
"`kubectl apply`를 통해 해당 워크로드를 실행할 수 있습니다. 결과는 `kubectl logs`를 통해 얻을 수 있으며 "
"워크로드의 상태는 `kubectl describe`로 확인할 수 있습니다. 실행이 끝난 워크로드는 `kubectl delete`를 통해 "
"삭제할 수 있습니다. 워크로드를 삭제하지 않으면 리소스 쿼터를 계속 점유하게 되므로, 사용이 끝난 워크로드는 결과 확인 후 삭제해주셔야 "
"다른 워크로드를 실행할 수 있습니다."
msgstr ""

#: src/container.md:34
msgid ""
"```sh\n"
"$ kubectl apply -f nginx-pod.yaml\n"
"pod/nginx-pod created\n"
"$ kubectl logs nginx-pod\n"
"Hello, world!\n"
"$ kubectl describe pods nginx-pod\n"
"...\n"
"$ kubectl delete pods nginx-pod\n"
"pod \"nginx-pod\" deleted\n"
"```"
msgstr ""

#: src/container.md:47
msgid "실행 중인 컨테이너를 아래와 같은 명령어로 접속할 수 있습니다."
msgstr ""

#: src/container.md:49
msgid ""
"```sh\n"
"$ kubectl exec nginx-pod -it -- /bin/sh\n"
"```"
msgstr ""

#: src/container.md:53
msgid ""
"이를 악용하여, **GPU 자원을 할당한 채 무한 루프를 명령어로 제출한 후 컨테이너에 직접 접속해서 코딩 및 실험을 해서는 "
"안됩니다.** GPU 등의 자원을 제대로 사용하지 않고 독점할 수 있기 때문입니다. 해당 행위는 절대 금물이며 바쿠스는 지속적으로 "
"모니터링을 하여 이를 단속합니다. **Jupyter Notebook와 같은 서버를 띄워두고 port-forwarding을 통해 접속하는 "
"것 역시 금지입니다.** 파이썬 스크립트로 변환 후 제출하는 방식으로 부탁드립니다."
msgstr ""

#: src/container.md:55
msgid ""
"다만, GPU 자원 없이 소수의 vCPU를 할당하여 퍼시스턴트 볼륨을 셋업하는 등의 예외적인 경우는 어쩔 수 없는 부분입니다. 자유로운 "
"사용을 위해 많은 기능들을 자유롭게 열어두었으니 여러분의 양심에 맡깁니다. 바람직한 사용법은 워크플로우 예시 부분에서 확인할 수 있습니다."
msgstr ""

#: src/volume.md:1
msgid "# 퍼시스턴트 볼륨 설정"
msgstr ""

#: src/volume.md:3
msgid ""
"컨테이너 내부 스토리지에 쓴 데이터, 로그 파일 등은 ephemeral-storage에 저장됩니다. 이 임시 스토리지는 컨테이너 삭제 시 "
"같이 소멸되므로 데이터셋이나 실행 결과 등을 저장하기에는 부적합합니다. 따라서 SNUCSE GPU 서비스는 ZFS 기반의 퍼시스턴트 "
"볼륨을 추가로 제공합니다. 여러분은 퍼시스턴트 볼륨 클레임을 통해서 이 퍼시스턴트 볼륨의 일부를 사용할수 있습니다. 다음 예시 "
"`nginx-pvc.yaml`는 30GiB의 퍼시스턴트 볼륨 클레임을 생성하는 예시입니다."
msgstr ""

#: src/volume.md:5
msgid ""
"```yaml\n"
"# nginx-pvc.yaml\n"
"kind: PersistentVolumeClaim\n"
"apiVersion: v1\n"
"metadata:\n"
"  name: nginx-pvc\n"
"spec:\n"
"  accessModes:\n"
"    - ReadWriteOnce\n"
"  resources:\n"
"    requests:\n"
"      storage: 30Gi\n"
"```"
msgstr ""

#: src/volume.md:19
msgid ""
"```sh\n"
"$ kubectl apply -f nginx-pvc.yaml\n"
"persistentvolumeclaim/nvinx-pvc created\n"
"```"
msgstr ""

#: src/volume.md:24
msgid "아래는 생성한 퍼시스턴트 볼륨 클레임을 통해 볼륨을 `/dataset`에 마운트하는 예시입니다."
msgstr ""

#: src/volume.md:26
msgid ""
"```yaml\n"
"# nginx-pod.yaml\n"
"apiVersion: v1\n"
"kind: Pod\n"
"metadata:\n"
"  name: nginx-pod\n"
"spec:\n"
"  restartPolicy: Never\n"
"  containers:\n"
"  - name: nginx-container\n"
"    image: \"nginx:latest\"\n"
"    command: [\"echo\"]\n"
"    args: [\"Hello, world!\"]\n"
"    resources:\n"
"      requests:\n"
"        cpu: 2\n"
"        memory: \"1Gi\"\n"
"    volumeMounts:\n"
"    - mountPath: \"/dataset\"\n"
"      name: nginx-pv\n"
"  volumes:\n"
"  - name: nginx-pv\n"
"    persistentVolumeClaim:\n"
"      claimName: nginx-pvc\n"
"```"
msgstr ""

#: src/volume.md:52
msgid "`/dataset` 경로에 데이터셋 및 결과를 저장하면 컨테이너 삭제 후에도 데이터가 보존됩니다."
msgstr ""

#: src/registry.md:1
msgid "# 이미지 레지스트리 이용"
msgstr ""

#: src/registry.md:3
msgid "사용하실 개인 이미지 레지스트리가 없으신 유저분들을 위해서 Bacchus는 레지스트리를 각 GPU 노드에서 제공합니다."
msgstr ""

#: src/registry.md:7
msgid ""
"현재로서는 만드실 수 있는 Project의 개수를 제한하고 있지는 않습니다. 하지만 다른 이용자들도 함께 이용하는 서비스이므로 **한 "
"유저 당 1개의 Project만 만들어서 사용하시길 바랍니다.** 각 Project는 기본적으로 30GB의 스토리지 Quota를 가지고 "
"있습니다."
msgstr ""

#: src/registry.md:9
msgid ""
"만약 어떤 유저가 Project를 무분별하게 만들어서 다른 유저들이 스토리지 공간이 부족해지는 경우가 생기게 된다면, 그 유저의 "
"Project들은 예고 없이 삭제될 수 있고, 향후 GPU 서비스의 이용이 제한될 예정입니다."
msgstr ""

#: src/registry.md:11
msgid "## 제공 중인 레지스트리"
msgstr ""

#: src/registry.md:13
msgid "현재 제공되고 있는 레지스트리는 다음과 같습니다."
msgstr ""

#: src/registry.md:15
msgid ""
"* [ferrari](https://registry.ferrari.snucse.org:30443/)\n"
"* [bentley](https://registry.bentley.snucse.org:30443/)"
msgstr ""

#: src/registry.md:18
msgid "## 이용 방법"
msgstr ""

#: src/registry.md:20
msgid "### 프로젝트 생성"
msgstr ""

#: src/registry.md:22
msgid ""
"1. 이용하고 싶은 레지스트리의 URL에 접속하고, `LOGIN VIA OIDC PROVIDER` 버튼을 통해서 로그인합니다.\n"
"1. 좌측의 `Projects` 탭으로 이동하고, `New Project` 버튼을 눌러서 새로운 프로젝트를 생성합니다."
msgstr ""

#: src/registry.md:25
msgid "### 레지스트리 로그인"
msgstr ""

#: src/registry.md:27
msgid ""
"기본적으로 다른 이미지 레지스트리를 사용하는 방법과 같습니다. 이 경우 CLI에서 로그인을 해야하는데, 이 때 사용되는 "
"Credential은 다음과 같습니다."
msgstr ""

#: src/registry.md:29
msgid "* `Username`: ID username\n* `Password`: CLI secret"
msgstr ""

#: src/registry.md:32
msgid "`CLI secret`을 얻기 위해서는 다음을 따릅니다."
msgstr ""

#: src/registry.md:34
msgid ""
"1. 우측 상단의 버튼에서 `User Profile`을 누릅니다.\n"
"1. CLI Secret 란의 오른쪽에 있는 Copy 버튼을 눌러서 클립보드에 시크릿을 복사합니다."
msgstr ""

#: src/registry.md:37
msgid "이후, CLI에서 다음과 같이 로그인합니다."
msgstr ""

#: src/registry.md:39
msgid ""
"```sh\n"
"# 사용할 레지스트리에 따라서 URL은 바뀌게 됩니다. 여기서는 ferrari의 레지스트리를 예시로 들겠습니다.\n"
"$ docker login https://registry.ferrari.snucse.org:30443/\n"
"\n"
"# 이후 prompt에서 물어보는 username과 password를 입력합니다.\n"
"```"
msgstr ""

#: src/registry.md:46
msgid "### Private Registry의 이미지를 Pod에서 사용하기"
msgstr ""

#: src/registry.md:48
msgid ""
"Pod에서 Private 공개범위의 레지스트리를 이용하기 위해서는, Pod에게 이미지를 가져올 때 사용할 크레덴셜을 제공해줄 필요가 "
"있습니다."
msgstr ""

#: src/registry.md:50
msgid "다음과 같은 명령어로 `Secret` 리소스를 생성합니다. 여기서는 `ferrari`를 예시로 듭니다."
msgstr ""

#: src/registry.md:52
msgid ""
"```sh\n"
"$ kubectl create secret docker-registry regcred \\\n"
"    --docker-server=registry.ferrari.snucse.org:30443 \\\n"
"    --docker-username='<ID Username>' \\\n"
"    --docker-password='<CLI Secret>'\n"
"```"
msgstr ""

#: src/registry.md:59
msgid ""
"`regcred` 라는 이름의 시크릿 리소스를 생성하고 나면, PodSpec에 `imagePullSecrets`를 다음과 같이 "
"추가합니다. 여기서는 `alpine` 이미지를 예시로 듭니다."
msgstr ""

#: src/registry.md:61
msgid ""
"```sh\n"
"apiVersion: v1\n"
"kind: Pod\n"
"metadata:\n"
"  name: alpine\n"
"spec:\n"
"  containers:\n"
"    - image: registry.ferrari.snucse.org:30443/<username>/alpine:latest\n"
"      command:\n"
"        - /bin/sh\n"
"        - \"-c\"\n"
"        - \"sleep 60m\"\n"
"      imagePullPolicy: IfNotPresent\n"
"      name: alpine\n"
"      resources:\n"
"        limits:\n"
"          cpu: 100m\n"
"          memory: 100Mi\n"
"  imagePullSecrets:\n"
"    - name: regcred\n"
"  restartPolicy: Always\n"
"```"
msgstr ""

#: src/example.md:1
msgid "# 워크플로우 예시"
msgstr ""

#: src/example.md:3
msgid ""
"모델 사이즈가 263.9GiB인 Llama-2-70b 모델을 40GB HBM2 A100이 8장 있는 bentley 서버에 올리는 예시를 "
"들어겠습니다."
msgstr ""

#: src/example.md:5
msgid "## 퍼시스턴트 볼륨 클레임 생성"
msgstr ""

#: src/example.md:7
msgid "먼저 충분한 자원 할당량이 있는지 확인합니다. 아래의 경우는 테스트를 위해 할당량을 크게 잡은 상태입니다."
msgstr ""

#: src/example.md:9
msgid ""
"```sh\n"
"$ kubectl get resourcequotas\n"
"NAME      AGE   REQUEST\n"
"deadbeef   3m   requests.cpu: 0/224, requests.memory: 0/896Gi, "
"requests.nvidia.com/gpu: 0/8, requests.storage: 0/1000Gi\n"
"```"
msgstr ""

#: src/example.md:15
msgid "모델이 들어가기에 충분하도록 300GB의 퍼시스턴트 볼륨 클레임, `llama-2-70b-pvc.yaml`을 먼저 생성하겠습니다."
msgstr ""

#: src/example.md:17
msgid ""
"```yaml\n"
"# llama-2-70b-pvc.yaml\n"
"kind: PersistentVolumeClaim\n"
"apiVersion: v1\n"
"metadata:\n"
"  name: llama-2-70b-pvc\n"
"spec:\n"
"  accessModes:\n"
"    - ReadWriteOnce\n"
"  resources:\n"
"    requests:\n"
"      storage: 300Gi\n"
"```"
msgstr ""

#: src/example.md:31
msgid ""
"```sh\n"
"$ kubectl apply -f llama-2-70b-pvc.yaml\n"
"persistentvolumeclaim/llama-2-70b-pvc created\n"
"```"
msgstr ""

#: src/example.md:36
msgid "## 이미지 빌드"
msgstr ""

#: src/example.md:38
msgid ""
"Llama 2는 Pytorch 및 CUDA 환경을 사용합니다. 이들이 미리 세팅된 "
"`nvcr.io/nvidia/pytorch:23.06-py3` 이미지를 베이스로 사용하겠습니다. 이미지는 어느 곳에서 어떠한 방식으로 "
"빌드해도 상관이 없지만 예시에서는 로컬에서 Dockerfile을 작성하여 빌드했습니다. 아래는 빌드에 사용된 Dockerfile입니다."
msgstr ""

#: src/example.md:40
msgid ""
"```dockerfile\n"
"# Dockerfile\n"
"FROM nvcr.io/nvidia/pytorch:23.06-py3\n"
"\n"
"RUN apt-get update && apt-get install -y wget git\n"
"\n"
"WORKDIR /\n"
"RUN git clone https://github.com/facebookresearch/llama.git\n"
"RUN cd llama && pip install -e .\n"
"```"
msgstr ""

#: src/example.md:51
msgid ""
"해당 빌드는 로컬에 보관할 수도 있고, 제공한 Harbor 레지스트리에 보관할 수도 있습니다. 제공한 레지스트리를 이용할 경우 서버의 "
"로컬 스토리지에 이미지가 저장되므로 컨테이너 실행 시 이미지를 고속으로 pull할 수 있습니다. Harbor에 올려서 사용하는 시나리오를 "
"예로 들겠습니다. private registry의 credential은 regcred로 생성됐다고 가정하겠습니다."
msgstr ""

#: src/example.md:53
msgid ""
"```sh\n"
"# https://registry.bentley.snucse.org:30443 에 deadbeef라는 private project가 "
"있다고 가정\n"
"$ docker login https://registry.bentley.snucse.org:30443/  # ID username과 "
"CLI secret 입력\n"
"$ docker build -t registry.bentley.snucse.org:30443/deadbeef/llama:latest - "
"< Dockerfile\n"
"$ docker push registry.bentley.snucse.org:30443/deadbeef/llama:latest\n"
"```"
msgstr ""

#: src/example.md:60
msgid "## 모델 파라미터 다운로드"
msgstr ""

#: src/example.md:62
msgid ""
"```yaml\n"
"# llama-2-70b-download.yaml\n"
"apiVersion: v1\n"
"kind: Pod\n"
"metadata:\n"
"  name: llama-2-70b-download\n"
"spec:\n"
"  restartPolicy: Never\n"
"\n"
"  containers:\n"
"  - name: llama-2-70b-container\n"
"    image: \"registry.bentley.snucse.org:30443/deadbeef/llama:latest\"\n"
"    command: [\"/bin/bash\"]\n"
"    args: [\"-c\", \"cd /data; echo \\\"$URL_FROM_EMAIL\\n"
"$MODELS_TO_DOWNLOAD\\\" | /llama/download.sh;\"]\n"
"    imagePullPolicy: IfNotPresent\n"
"    resources:\n"
"      limits:\n"
"        cpu: 4\n"
"        memory: \"1Gi\"\n"
"    volumeMounts:\n"
"    - mountPath: \"/data\"\n"
"      name: llama-2-70b-pv\n"
"    env:\n"
"    - name: URL_FROM_EMAIL\n"
"      value: \"the URL from email\"\n"
"    - name: MODELS_TO_DOWNLOAD\n"
"      value: \"70B\"\n"
"  volumes:\n"
"  - name: llama-2-70b-pv\n"
"    persistentVolumeClaim:\n"
"      claimName: llama-2-70b-pvc\n"
"  imagePullSecrets:\n"
"  - name: regcred\n"
"```"
msgstr ""

#: src/example.md:97
msgid ""
"위 예시에서 `URL_FROM_EMAIL`을 채워넣은 후 실행하여 퍼시스턴트 볼륨에 모델 파라미터를 다운로드합니다.\n"
"Llama-2 모델 파라미터 다운로드 시 이메일을 입력이 필요한 이유는 Meta의 요구사항이며 다른 모델들은 각자의 방식으로 "
"다운로드하시면 됩니다."
msgstr ""

#: src/example.md:100
msgid ""
"```sh\n"
"$ kubectl apply -f llama-2-70b-download.yaml\n"
"pod/llama-2-70b-download created\n"
"```"
msgstr ""

#: src/example.md:105
msgid "다운로드가 완료되면 완료된 pod을 지우고 실제 실험 컨테이너를 실행합니다."
msgstr ""

#: src/example.md:107
msgid ""
"```sh\n"
"$ kubectl delete pods llama-2-70b-download\n"
"pod \"llama-2-70b-download\" deleted\n"
"```"
msgstr ""

#: src/example.md:112
msgid ""
"위와 같이 데이터셋 및 모델 weight를 준비할 때 GPU 없이 소수의 CPU와 메모리만 할당하여 준비하시기 바랍니다.\n"
"스크립트를 한번에 짜서 준비하는 게 어려울 경우"
msgstr ""

#: src/example.md:115
msgid ""
"```yaml\n"
"    command: [ \"/bin/bash\", \"-c\", \"--\" ]\n"
"    args: [ \"while true; do sleep 30; done;\" ]\n"
"```"
msgstr ""

#: src/example.md:120
msgid ""
"와 같이 무한루프를 제출하고 `kubectl exec`으로 접속하여 퍼시스턴트 볼륨 내 데이터를 준비할 수 있습니다.\n"
"세팅이 끝나면 반드시 해당 pod을 삭제해주시기 바랍니다."
msgstr ""

#: src/example.md:123
msgid "## 테스트 실행"
msgstr ""

#: src/example.md:125
msgid ""
"```yaml\n"
"# llama-2-70b-run.yaml\n"
"apiVersion: v1\n"
"kind: Pod\n"
"metadata:\n"
"  name: llama-2-70b-run\n"
"spec:\n"
"  restartPolicy: Never\n"
"\n"
"  containers:\n"
"  - name: llama-2-70b-container\n"
"    image: \"registry.bentley.snucse.org:30443/deadbeef/llama:latest\"\n"
"    command: [\"torchrun\"]\n"
"    args: [\"--nproc_per_node\", \"8\", "
"\"/llama/example_text_completion.py\", \\\n"
"        \"--ckpt_dir\", \"llama-2-70b\", \"--tokenizer_path\", "
"\"tokenizer.model\", \\\n"
"        \"--max_seq_len 128\", \"--max_batch_size\", \"4\"]\n"
"    imagePullPolicy: IfNotPresent\n"
"    resources:\n"
"      limits:\n"
"        cpu: 224\n"
"        memory: \"896Gi\"\n"
"        nvidia.com/gpu: 8\n"
"    volumeMounts:\n"
"    - mountPath: \"/data\"\n"
"      name: llama-2-70b-pv\n"
"  volumes:\n"
"  - name: llama-2-70b-pv\n"
"    persistentVolumeClaim:\n"
"      claimName: llama-2-70b-pvc\n"
"  imagePullSecrets:\n"
"  - name: regcred\n"
"```"
msgstr ""

#: src/example.md:158
msgid ""
"```sh\n"
"$ kubectl apply -f llama-2-70b-run.yaml\n"
"pod/llama-2-70b-run created\n"
"```"
msgstr ""

#: src/example.md:163
msgid "## 기타"
msgstr ""

#: src/example.md:165
msgid ""
"소스코드를 수정하거나 패키지를 추가 설치해야 하는 등의 경우 이미지를 다시 빌드한 후 레지스트리에 push해야 합니다. 이미지 빌드 "
"시에는 Dockerfile을 작성하거나 `docker commit`을 이용하면 됩니다. 연구 특성상 소스코드 수정 후 실행을 자주 "
"반복해야 하는 경우가 많습니다. 이때 이미지 레이어가 캐싱되는 것을 고려하지 않은 채 빌드하게 되면 매번 큰 양의 데이터가 네트워크를 "
"통해 전송되게 되므로 수정 후 실행 주기가 길어질 수밖에 없습니다. 이미지 레이어 캐싱을 고려해서 빌드해주시기 바랍니다. 소스코드를 "
"Github에 올린 후 Github Action과 Github Packages를 이용하여 이미지를 자동 빌드하는 방법도 좋고 `git "
"clone`해서 `docker build`하는 방법도 좋습니다. 자유롭게 사용하시면 됩니다. 빌드를 자주해야 할 경우 커맨드를 여럿 "
"묶어서 스크립트로 짜면 좋습니다."
msgstr ""

#: src/example.md:167
msgid ""
"퍼시스턴트 볼륨으로 파일을 보내거나 꺼내야 하는 경우 `kubectl cp`를 사용하면 됩니다. (`kubectl cp --help` "
"참고) 이때 퍼시스턴트 볼륨이 pod과 붙어 있어야 하므로 무한루프를 걸어 소수의 vCPU와 함께 Pod을 띄운 후 데이터를 주고 받으면 "
"됩니다."
msgstr ""

#: src/developers.md:1
msgid "# 개발팀"
msgstr ""

#: src/developers.md:5
msgid "팀장"
msgstr ""

#: src/developers.md:6
msgid "- **백우현** / 컴퓨터공학부 17"
msgstr ""

#: src/developers.md:8
msgid "팀원"
msgstr ""

#: src/developers.md:9
msgid ""
"- **김무환** / 컴퓨터공학부 17\n"
"- **김민준** / 수 리 과 학 부 23\n"
"- **박재현** / 컴퓨터공학부 16\n"
"- **박종훈** / 컴퓨터공학부 15\n"
"- **박찬우** / 경 &nbsp;&nbsp;영 &nbsp;학 &nbsp;&nbsp;과 17\n"
"- **서지민** / 컴퓨터공학부 20\n"
"- **성용운** / 컴퓨터공학부 17\n"
"- **오평석** / 컴퓨터공학부 13\n"
"- **오하나** / 자유전공학부 19\n"
"- **윤지학** / 컴퓨터공학부 16\n"
"- **이준혁** / 컴퓨터공학부 17\n"
"- **최원우** / 컴퓨터공학부 16"
msgstr ""

#: src/developers.md:22
msgid "도움 주신 분들"
msgstr ""

#: src/developers.md:23
msgid "- **이재욱** 교수님\n- **전병곤** 교수님"
msgstr ""

